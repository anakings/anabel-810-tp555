{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probCond(x, y, C, a, V):\n",
    "    count = 0\n",
    "    sum_count = 0\n",
    "    #y.reshape((len(y),1))\n",
    "    x2 = x[:]\n",
    "    for i, value_y in enumerate(y):\n",
    "        if value_y == C:\n",
    "            count = count + (len(x2[i].split(a)) - 1) # contagem(xk,Cq)\n",
    "            sum_count = sum_count + len(x[i].split(' ')) # a soma total de palavras pertencentes à classe Cq\n",
    "    \n",
    "    probCond = (count + 1) / (sum_count + V)\n",
    "    return probCond\n",
    "\n",
    "def calculate_probability(x, y, xTest, print_a_priori=True):\n",
    "    listNoRepClass = []\n",
    "    for j in y:\n",
    "        if j not in listNoRepClass:\n",
    "            listNoRepClass.append(j) # I have the classes\n",
    "    \n",
    "    quantity = []\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for j in listNoRepClass:\n",
    "        for i in y:\n",
    "            if i == j: count += 1\n",
    "        quantity.append(count) # Now in quantity is how many times a class is repeated\n",
    "        total = total + count\n",
    "        count = 0\n",
    "    \n",
    "    proClass = [j / total for j in quantity] # Probability for each class (priori) \n",
    "    \n",
    "    x1 = x[:]\n",
    "    listNoRepAtr = []\n",
    "    for i in x1:\n",
    "        listx = i.split(' ') \n",
    "        for j in listx:\n",
    "            if j not in listNoRepAtr:\n",
    "                listNoRepAtr.append(j)\n",
    "    V = len(listNoRepAtr) # tamanho do vocabulário\n",
    "    \n",
    "    probabilityXtest = 1\n",
    "    Posteriori = []\n",
    "    for index, j in enumerate(listNoRepClass):\n",
    "        for i in xTest: \n",
    "            probabilityCon = calculate_probCond(x, y, j, i, V)\n",
    "            probabilityXtest = probabilityXtest*probabilityCon\n",
    "        Posteriori.append(probabilityXtest*proClass[index])\n",
    "        probabilityXtest = 1      \n",
    "    \n",
    "    for index, j in enumerate(listNoRepClass):\n",
    "        print('A probabilidade da classe \"' + str(j) + '\" a posteriori é ' + str(Posteriori[index]))\n",
    "    if print_a_priori == True:\n",
    "        print('')\n",
    "        for index, j in enumerate(listNoRepClass):\n",
    "            print('A probabilidade da classe \"' + str(j) + '\" a priori é ' + str(proClass[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(['Chinese Beijing Chinese', 'Chinese Chinese Shanghai', 'Chinese Macao', 'Tokyo Japan Chinese'])\n",
    "y_train = np.array(['china','china','china','not china'])\n",
    "y_1 = np.copy(y_train)\n",
    "for i in range(0,len(y_train)):\n",
    "    if y_1[i] == 'china': y_train[i] = 1\n",
    "    else: y_train[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(['Chinese Chinese Chinese Tokyo Japan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a collection of text documents into a matrix of token counts.\n",
    "vect = CountVectorizer(binary=True)\n",
    "# Learn the vocabulary dictionary and return term-document matrix.\n",
    "# This is equivalent to fit followed by transform, but more efficiently implemented.\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Bernoulli Naive Bayes model.\n",
    "nb = BernoulliNB(binarize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=None, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the BernoulliNB model.\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a)\n",
      "Nome dos atributos:\n",
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n",
      "\n",
      "Matriz de contagem dos atributos para cada uma das instâncias de CountVectorizer\n",
      "[[1 1 0 0 0 0]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 1 0 0]\n",
      " [0 1 1 0 0 1]]\n",
      "\n",
      "b)\n",
      "A mensagem \"Chinese Chinese Chinese Tokyo Japan\" pertence à classe \"not china\".\n"
     ]
    }
   ],
   "source": [
    "# Transform document into document-term matrix.\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "# Perform classification on an array of test vectors X_test_dtm.\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "if y_pred_class == '1': y_pred_class = 'china'\n",
    "else: y_pred_class = 'not china'\n",
    "    \n",
    "print('a)\\nNome dos atributos:')\n",
    "print(vect.get_feature_names())\n",
    "print('\\nMatriz de contagem dos atributos para cada uma das instâncias de CountVectorizer')\n",
    "print(X_train_dtm.toarray())\n",
    "\n",
    "print('\\nb)\\nA mensagem \"'+  X_test[0] + '\" pertence à classe \"' + y_pred_class + '\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a collection of text documents to a matrix of token counts.\n",
    "cv = CountVectorizer()\n",
    "# Naive Bayes classifier for multinomial models.\n",
    "mnb = MultinomialNB()\n",
    "# Create a pipeline that attaches the vectorizer to a multinomial naive Bayes classifier.\n",
    "model = make_pipeline(cv, mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a)\n",
      "Nome dos atributos:\n",
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n",
      "\n",
      "Matriz de contagem dos atributos para cada uma das instâncias de CountVectorizer\n",
      "[[1 2 0 0 0 0]\n",
      " [0 2 0 0 1 0]\n",
      " [0 1 0 1 0 0]\n",
      " [0 1 1 0 0 1]]\n",
      "\n",
      "b)\n",
      "A mensagem \"Chinese Chinese Chinese Tokyo Japan\" pertence à classe \"china\".\n"
     ]
    }
   ],
   "source": [
    "# Train model. Apply the model to the training data.\n",
    "model.fit(X_train, y_train)\n",
    "# Run validation. Predict labels for the test data.\n",
    "y_pred_class = model.predict(X_test)\n",
    "if y_pred_class == '1': y_pred_class = 'china'\n",
    "else: y_pred_class = 'not china'\n",
    "\n",
    "X_train_dtm = cv.fit_transform(X_train)\n",
    "print('a)\\nNome dos atributos:')\n",
    "print(vect.get_feature_names())\n",
    "print('\\nMatriz de contagem dos atributos para cada uma das instâncias de CountVectorizer')\n",
    "print(X_train_dtm.toarray())\n",
    "\n",
    "print('\\nb)\\nA mensagem \"'+  X_test[0] + '\" pertence à classe \"' + y_pred_class + '\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c)\n",
      "A probabilidade da classe \"china\" a posteriori é 0.00030121377997263036\n",
      "A probabilidade da classe \"not china\" a posteriori é 0.00013548070246744226\n",
      "\n",
      "A probabilidade da classe \"china\" a priori é 0.75\n",
      "A probabilidade da classe \"not china\" a priori é 0.25\n"
     ]
    }
   ],
   "source": [
    "print('c)')\n",
    "X_test1 = X_test[0].split(' ')\n",
    "probability = calculate_probability(X_train, y_1, X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d)\n",
      "Nome dos atributos:\n",
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n",
      "\n",
      "Vetor de contagens de cada classificador em Bernoulli:\n",
      "[[0 1 1 0 0 1]]\n",
      "\n",
      "Vetor de contagens de cada classificador em Multinomial:\n",
      "[[0 3 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#probability = calculate_probability(X_test, y_pred_class)\n",
    "print('d)')\n",
    "print('Nome dos atributos:')\n",
    "print(vect.get_feature_names())\n",
    "print('\\nVetor de contagens de cada classificador em Bernoulli:')\n",
    "print(X_test_dtm.toarray())\n",
    "X_test_dtm1 = cv.transform(X_test)\n",
    "print('\\nVetor de contagens de cada classificador em Multinomial:')\n",
    "print(X_test_dtm1.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No caso do Bernoulli o vetor de contagens somente apresenta se existe a palavra ou não, isso faz com que ele interprete uma ocurrência para a clase \"china \" e duas ocurrências para a classe \"not china\". Como têm maior quantidade de ocurrências para a classe \"not china\", o modelo treinado com Bernoulli prediz erroneamente que a mensagem pertence à classe \"not china\".\n",
      "\n",
      "No caso do Multinomial o vetor de contagens apresenta se existe a palavra e as vezes que ela se repite, isso faz como que ele interprete três ocurrências para a classe \"china\" e duas ocurrências para a classe \"not china\". Como têm maior quantidade de ocurrências para a classe \"china\", o modelo treinado com Multinomial prediz corretamente que a mensagem pertence à classe \"china\".\n",
      "\n",
      "Então, em Bernoulli, é como se a mensagem (X_test1) fosse ['Chinese', 'Tokyo', 'Japan'] y em Multinomial fosse ['Chinese Chinese Chinese Tokyo Japan']. Agora vou a calcular manualmente a probabilidade de cada classe, ou seja, ‘china’ e ‘not china’, para cada mensagem de teste para os 2 classificadores.\n",
      "\n",
      "Probabilidade de cada classificador em Bernoulli:\n",
      "A probabilidade da classe \"china\" a posteriori é 0.001639941690962099\n",
      "A probabilidade da classe \"not china\" a posteriori é 0.0027434842249657062\n",
      "\n",
      "Probabilidade de cada classificador em Multinomial:\n",
      "A probabilidade da classe \"china\" a posteriori é 0.00030121377997263036\n",
      "A probabilidade da classe \"not china\" a posteriori é 0.00013548070246744226\n"
     ]
    }
   ],
   "source": [
    "print('No caso do Bernoulli o vetor de contagens somente apresenta se existe a palavra ou não, isso faz com que ele interprete uma ocurrência para a clase \"china \" e duas ocurrências para a classe \"not china\". Como têm maior quantidade de ocurrências para a classe \"not china\", o modelo treinado com Bernoulli prediz erroneamente que a mensagem pertence à classe \"not china\".\\n')\n",
    "print('No caso do Multinomial o vetor de contagens apresenta se existe a palavra e as vezes que ela se repite, isso faz como que ele interprete três ocurrências para a classe \"china\" e duas ocurrências para a classe \"not china\". Como têm maior quantidade de ocurrências para a classe \"china\", o modelo treinado com Multinomial prediz corretamente que a mensagem pertence à classe \"china\".\\n')\n",
    "print(\"Então, em Bernoulli, é como se a mensagem (X_test1) fosse ['Chinese', 'Tokyo', 'Japan'] y em Multinomial fosse ['Chinese Chinese Chinese Tokyo Japan']. Agora vou a calcular manualmente a probabilidade de cada classe, ou seja, ‘china’ e ‘not china’, para cada mensagem de teste para os 2 classificadores.\")\n",
    "\n",
    "print('\\nProbabilidade de cada classificador em Bernoulli:')\n",
    "X_test1 = ['Chinese', 'Tokyo', 'Japan']\n",
    "probability1 = calculate_probability(X_train, y_1, X_test1, print_a_priori=False)\n",
    "\n",
    "print('\\nProbabilidade de cada classificador em Multinomial:')\n",
    "X_test1 = ['Chinese', 'Chinese', 'Chinese', 'Tokyo', 'Japan']\n",
    "X_test1 = X_test[0].split(' ')\n",
    "probability = calculate_probability(X_train, y_1, X_test1, print_a_priori=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pode-se verificar que a probabilidade a posteriori no classificador do Bernoulli é maior para a classe \"not china\" e em Multinomial é maior para a classe \"china\", do mesmo jeito que o metodo implementado pela libreria sklearn.\n"
     ]
    }
   ],
   "source": [
    "print('Pode-se verificar que a probabilidade a posteriori no classificador do Bernoulli é maior para a classe \"not china\" e em Multinomial é maior para a classe \"china\", do mesmo jeito que o metodo implementado pela libreria sklearn.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
